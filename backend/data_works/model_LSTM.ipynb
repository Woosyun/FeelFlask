{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 11:09:53.195709: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-30 11:09:53.199523: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-30 11:09:53.235695: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-30 11:09:53.915023: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/ysy/.local/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "s : 0.3913968438320654, d : 0.8028839669421488, a : 0.6096858638743454, t : 0.5435714285714286\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "s : 0.46726931351599776, d : 0.802886347107438, a : 0.9857493206071452, t : 0.5218996960486322\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "s : 0.5102102672463287, d : 0.8028839669421488, a : 0, t : 0.4642857142857143\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "s : 0.5102102672463287, d : 0.8028839669421488, a : 0.9879154078549849, t : 0.49857142857142855\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "s : 0.5477225575051662, d : 0.8028839669421488, a : 0.9965635738831616, t : 0.6299999999999999\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_457919/1216282229.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;31m# 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperformance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecipe_generation_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_recipes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0mrecipe_generation_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'testmodel.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_457919/1216282229.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, recipes, epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0mthreshold_performance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mthreshold_abv_match\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             threshold_taste_match,wandb.run.id) \n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from CocktailEmbeddingMaker import CocktailEmbeddingMaker\n",
    "from CocktailEmbeddingMaker import Eval\n",
    "import wandb\n",
    "# 데이터 로드\n",
    "with open('./train_data.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "with open('../flavor.json', 'r') as f:\n",
    "    flavor_data = json.load(f)\n",
    "test_user_list = []\n",
    "\n",
    "attributes = ['ABV', 'boozy', 'sweet', 'sour', 'bitter', 'umami', 'salty', 'astringent', 'Perceived_temperature', 'spicy', 'herbal', 'floral', 'fruity', 'nutty', 'creamy', 'smoky']\n",
    "user_num = 5\n",
    "for i in range(user_num):\n",
    "    user = {}\n",
    "    user['user_id'] = i\n",
    "    preference = {}\n",
    "    user['ABV'] = np.random.randint(0,60)\n",
    "    for attribute in attributes[2:]:\n",
    "        user[attribute] = np.random.randint(0,100)\n",
    "    test_user_list.append(user)\n",
    "\n",
    "# Random user_list 생성 및 저장\n",
    "def generate_random_user_list(num_users):\n",
    "    user_list = []\n",
    "    attributes = ['ABV', 'boozy', 'sweet', 'sour', 'bitter', 'umami', 'salty', 'astringent', 'Perceived_temperature', 'spicy', 'herbal', 'floral', 'fruity', 'nutty', 'creamy', 'smoky']\n",
    "\n",
    "    for i in range(num_users):\n",
    "        user = {\n",
    "            'user_id': i,\n",
    "            'ABV': np.random.randint(0, 60),\n",
    "        }\n",
    "        for attribute in attributes[2:]:\n",
    "            user[attribute] = np.random.randint(0, 100)\n",
    "        user_list.append(user)\n",
    "\n",
    "    with open(f'user_list_v1_{num_users}.json', 'w') as f:\n",
    "        json.dump(user_list, f)\n",
    "\n",
    "    print(\"Random user_list generated and saved.\")\n",
    "\n",
    "\n",
    "class RecipeGenerationModel:\n",
    "    #RecipeGenerationModel(cocktail_embedding_maker, wandb_flag=True, max_recipe_length=10)\n",
    "    def __init__(self, cocktail_embedding_maker,wandb_Flag=False, max_recipe_length=10):\n",
    "        self.cocktail_embedding_maker = cocktail_embedding_maker\n",
    "        self.ingredient_ids = cocktail_embedding_maker.ingredient_ids\n",
    "        self.num_ingredients = cocktail_embedding_maker.num_ingredients\n",
    "        self.max_recipe_length = max_recipe_length\n",
    "        self.ingredient_embedding_matrix = cocktail_embedding_maker.create_ingredient_embedding_matrix()\n",
    "        self.sweep_config = None\n",
    "        self.evaluation_metrics=None\n",
    "        self.sweep_id = None\n",
    "        self.wandb = wandb_Flag\n",
    "        self.model = self.build_model()\n",
    "        self.total_amount = 200\n",
    "        self.Eval = Eval(json_data,flavor_data,self.total_amount)\n",
    "        self.attributes = ['ABV', 'boozy', 'sweet', 'sour', 'bitter', 'umami', 'salty', 'astringent', 'Perceived_temperature', 'spicy', 'herbal', 'floral', 'fruity', 'nutty', 'creamy', 'smoky']\n",
    "        self.evaluation_metrics = ['diversity', 'abv_match', 'taste_match']\n",
    "        # Best 모델 판정 및 저장\n",
    "    def save_best_model(self, performance, abv_match, taste_match, threshold_performance, threshold_abv_match, threshold_taste_match,run_id):\n",
    "\n",
    "        if performance >= threshold_performance and abv_match >= threshold_abv_match and taste_match >= threshold_taste_match:\n",
    "            self.model.model.save(f'best_model_{run_id}.h5')\n",
    "            print(\"Best model saved.\")\n",
    "        else:\n",
    "            print(\"Model does not meet the threshold criteria.\")\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential([\n",
    "            Embedding(self.num_ingredients, self.ingredient_embedding_matrix.shape[1],\n",
    "                      weights=[self.ingredient_embedding_matrix], input_length=self.max_recipe_length, trainable=False),\n",
    "            LSTM(128, return_sequences=True),\n",
    "            LSTM(128),\n",
    "            Dense(64, activation='gelu'),\n",
    "            Dense(self.num_ingredients, activation='softmax')\n",
    "        ])\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def train(self, recipes, epochs=50, batch_size=32,learning_rate=0.001):\n",
    "        ingredient_sequences = []\n",
    "        next_ingredients = []\n",
    "\n",
    "        for recipe in recipes:\n",
    "            sequence = [self.ingredient_ids[self.cocktail_embedding_maker.normalize_string(ingredient)] for ingredient in recipe]\n",
    "            for i in range(1, len(sequence)):\n",
    "                ingredient_sequences.append(sequence[:i])\n",
    "                next_ingredients.append(sequence[i])\n",
    "\n",
    "        ingredient_sequences = tf.keras.preprocessing.sequence.pad_sequences(ingredient_sequences, maxlen=self.max_recipe_length)\n",
    "        next_ingredients = tf.keras.utils.to_categorical(next_ingredients, num_classes=self.num_ingredients)\n",
    "        evaluation_interval = 5\n",
    "        if self.wandb:\n",
    "            # wandb 초기화\n",
    "            wandb.init(project='cocktail_recipe_generation')\n",
    "\n",
    "\n",
    "        # for epoch in range(epochs):\n",
    "        history = self.model.fit(ingredient_sequences, next_ingredients, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "        loss = history.history['loss'][0]\n",
    "        accuracy = history.history['accuracy'][0]\n",
    "        if self.wandb:\n",
    "            # wandb 로깅\n",
    "            wandb.log({\n",
    "                'epoch': epochs,\n",
    "                'loss': loss,\n",
    "                'accuracy': accuracy,\n",
    "            })\n",
    "        # eval을 호출 해서 평가를 수행하고 결과를 evaluation_result에 저장한다. \n",
    "        # 저장후 evaluation_metrics에 지정된 평가 지표 합을 계산해서 performance변수에 저장한다. \n",
    "        #wandb에 performance와 개별 평가 지표결과를 로깅한다. \n",
    "            # 모델 평가\n",
    "        # print(\"evaluating model\")\n",
    "\n",
    "        evaluation_results,recipe_profile_list = self.Eval.evaluate_model(self.model, test_user_list)\n",
    "        if self.wandb:\n",
    "            for recipe_profile in recipe_profile_list:\n",
    "                for key in self.attributes:\n",
    "                    wandb.log({key: recipe_profile[key]})\n",
    "            \n",
    "       \n",
    "        # 평가 지표 계산\n",
    "        performance = sum(evaluation_results[metric] for metric in self.evaluation_metrics)\n",
    "                # Best 모델 판정 및 저장\n",
    "        threshold_performance = 2.07\n",
    "        threshold_abv_match = 0.656\n",
    "        threshold_taste_match = 0.616\n",
    "        \n",
    "        self.save_best_model(\n",
    "                            self.model, \n",
    "                            performance, \n",
    "                            evaluation_results['abv_match'], \n",
    "                            evaluation_results['taste_match'], \n",
    "                            threshold_performance, \n",
    "                            threshold_abv_match, \n",
    "                            threshold_taste_match,wandb.run.id) \n",
    "\n",
    "        if self.wandb:\n",
    "            # 평가 지표 로깅\n",
    "            wandb.log({'performance': performance, **evaluation_results})\n",
    "            wandb.finish()\n",
    "        return loss, accuracy, performance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # # 모델 학습\n",
    "# # recipe_generation_model.train(train_recipes, epochs=50, batch_size=32)\n",
    "# def train_with_sweep():\n",
    "#     # CocktailEmbeddingMaker 인스턴스 생성\n",
    "#     cocktail_embedding_maker = CocktailEmbeddingMaker(json_data, flavor_data)\n",
    "\n",
    "#     # RecipeGenerationModel 인스턴스 생성\n",
    "#     recipe_generation_model = RecipeGenerationModel(cocktail_embedding_maker, True, max_recipe_length=10)\n",
    "\n",
    "#     # 학습 데이터 준비\n",
    "#     train_recipes = [recipe['recipe'].keys() for recipe in json_data['cocktail_info']]\n",
    "\n",
    "#     # 모델 학습\n",
    "#     loss, accuracy, performance = recipe_generation_model.train(train_recipes)\n",
    "\n",
    "\n",
    "#     return loss, accuracy, performance\n",
    "\n",
    "\n",
    "\n",
    "# sweep_configuration = {\n",
    "#     'method': 'random',\n",
    "#     'name': 'sweep',\n",
    "#     'metric': {'goal': 'maximize', 'name': 'performance'},\n",
    "#     'parameters': \n",
    "#     {\n",
    "#         'batch_size': {'values': [16,32,64]},\n",
    "#         'epochs': {'values': [200,300]},\n",
    "#         'lr': {'max': 0.1, 'min': 0.07}\n",
    "#      }\n",
    "# }\n",
    "\n",
    "\n",
    "# sweep_id = wandb.sweep(sweep_configuration, project='cocktail_recipe_generation')\n",
    "# wandb.agent(sweep_id, function=train_with_sweep)\n",
    "\n",
    "cocktail_embedding_maker = CocktailEmbeddingMaker(json_data, flavor_data)\n",
    "\n",
    "# RecipeGenerationModel 인스턴스 생성\n",
    "recipe_generation_model = RecipeGenerationModel(cocktail_embedding_maker, False, max_recipe_length=10)\n",
    "\n",
    "# 학습 데이터 준비\n",
    "train_recipes = [recipe['recipe'].keys() for recipe in json_data['cocktail_info']]\n",
    "\n",
    "# 모델 학습\n",
    "loss, accuracy, performance = recipe_generation_model.train(train_recipes)\n",
    "recipe_generation_model.model.model.save(f'testmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "recipe_generation_model.model.save(f'testmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.restore('best_model.h5', run_path='wandb/run-20210929_062153-1v5z1z1o/files/best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "api = wandb.Api()\n",
    "run = api.run(\"jennyshin_gist_2024/cocktail_recipe_generation/a9k8jlwi\")\n",
    "best_hyperparams = run.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "WARNING:tensorflow:5 out of the last 52 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e8d763230a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 52 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e8d763230a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      " please ignore user_id!\n",
      "[INPUT] user preference: {\n",
      "    \"ABV\": 23,\n",
      "    \"boozy\": 99,\n",
      "    \"sweet\": 74,\n",
      "    \"sour\": 40,\n",
      "    \"bitter\": 82,\n",
      "    \"umami\": 5,\n",
      "    \"salty\": 40,\n",
      "    \"astringent\": 30,\n",
      "    \"Perceived_temperature\": 42,\n",
      "    \"spicy\": 53,\n",
      "    \"herbal\": 78,\n",
      "    \"floral\": 55,\n",
      "    \"fruity\": 95,\n",
      "    \"nutty\": 30,\n",
      "    \"creamy\": 45,\n",
      "    \"smoky\": 96\n",
      "}\n",
      "[OUTPUT]recipe!!!!: {'triple sec': 66.66666666666613, 'amaretto': 66.66666666666613, 'cider': 66.66666666666613} \n",
      "[OUTPUT]user_recipe's profile : {\n",
      "    \"ABV\": 22.333333333333332,\n",
      "    \"boozy\": 36.666666666666664,\n",
      "    \"sweet\": 53.33333333333333,\n",
      "    \"sour\": 6.666666666666666,\n",
      "    \"bitter\": 3.333333333333333,\n",
      "    \"umami\": 3.333333333333333,\n",
      "    \"salty\": 0.0,\n",
      "    \"astringent\": 3.333333333333333,\n",
      "    \"Perceived_temperature\": 26.666666666666664,\n",
      "    \"spicy\": 0.0,\n",
      "    \"herbal\": 6.666666666666666,\n",
      "    \"floral\": 13.333333333333332,\n",
      "    \"fruity\": 43.33333333333333,\n",
      "    \"nutty\": 10.0,\n",
      "    \"creamy\": 13.333333333333332,\n",
      "    \"smoky\": 0.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from CocktailEmbeddingMaker import Eval\n",
    "# 데이터 로드\n",
    "with open('./train_data.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "with open('../flavor.json', 'r') as f:\n",
    "    flavor_data = json.load(f)\n",
    "\n",
    "\n",
    "attributes = ['ABV', 'boozy', 'sweet', 'sour', 'bitter', 'umami', 'salty', 'astringent', 'Perceived_temperature', 'spicy', 'herbal', 'floral', 'fruity', 'nutty', 'creamy', 'smoky']\n",
    "#가상의 유저 만들기\n",
    "test_user_list = []\n",
    "user_num = 5\n",
    "for i in range(user_num):\n",
    "    user = {}\n",
    "    # user['user_id'] = i\n",
    "    preference = {}\n",
    "    user['ABV'] = np.random.randint(0,60)\n",
    "    for attribute in attributes[1:]:\n",
    "        user[attribute] = np.random.randint(0,100)\n",
    "    test_user_list.append(user)\n",
    "\n",
    "#음료의 총 량\n",
    "total_amount = 200\n",
    "#모델 로드\n",
    "load_model = keras.models.load_model('testmodel.h5')\n",
    "#Eval 객체 생성 -> inference용 전용 class가 필요하면 이야기할것\n",
    "Eval_obj = Eval(json_data,flavor_data,load_model)\n",
    "\n",
    "generated_recipes = Eval_obj.generate_recipe('triple sec',test_user_list[1],3)\n",
    "result_recipe ={}\n",
    "\n",
    "for recipe, ingredients in zip(generated_recipes[0], generated_recipes[1]):\n",
    "    result_recipe[recipe]=ingredients * total_amount\n",
    "user_recipe_profile = Eval_obj.get_taste_log(generated_recipes)\n",
    "\n",
    "print(\" please ignore user_id!\")\n",
    "print(f\"[INPUT] user preference: {json.dumps(test_user_list[1],indent=4)}\")\n",
    "print(f\"[OUTPUT]recipe!!!!: {result_recipe} \")\n",
    "print(f\"[OUTPUT]user_recipe's profile : {json.dumps(user_recipe_profile,indent=4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'vodka': 66.66666666666613},\n",
       " {'ouzo': 66.66666666666613},\n",
       " {'dry vermouth': 66.66666666666613}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "(['vodka', 'peach schnapps', 'chambord raspberry liqueur', 'midori melon liqueur'], [0.25, 0.25, 0.25, 0.25])\n",
      "[50.0, 50.0, 50.0, 50.0]\n"
     ]
    }
   ],
   "source": [
    "# Eval_obj.evaluate_model(load_model,test_user_list)\n",
    "generated_recipes = Eval_obj.generate_recipe('vodka',test_user_list[1],4)\n",
    "Eval_obj.get_taste_log(generated_recipes)\n",
    "total_amount = 200\n",
    "print(generated_recipes)\n",
    "print([item*total_amount for item in generated_recipes[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "['vodka', 'ouzo', 'dry vermouth']\n",
      "[0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065, 0.33333333333333065]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[66.66666666666613, 66.66666666666613, 66.66666666666613]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
